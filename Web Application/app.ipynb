{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b8b25-06d8-4705-af2e-a334f1ea68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:56] \"GET /static/doc.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:56] \"GET /static/detect.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:56] \"GET /static/report.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:56] \"GET /static/mental.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:58] \"GET /ModulesPage HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:58] \"GET /static/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:58] \"GET /static/detect.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:58] \"GET /static/report.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:08:58] \"GET /static/mental.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:09:01] \"GET /FallDetection HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:09:01] \"GET /static/fall-2.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:09:01] \"GET /static/fall.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [24/Jan/2025 20:09:02] \"GET /upload-video HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video uploaded to: static/uploads/video.mp4\n",
      "Processing video: static/processed/video.mp4\n",
      "Input_video=static/uploads/video.mp4\n",
      "video open\n",
      "frame,height,width got\n",
      "out declared\n",
      "variable initialized\n",
      "\n",
      "0: 480x640 1 person, 108.6ms\n",
      "Speed: 0.0ms preprocess, 108.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame detected\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 47.7ms\n",
      "Speed: 12.0ms preprocess, 47.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 45.9ms\n",
      "Speed: 15.5ms preprocess, 45.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 48.0ms\n",
      "Speed: 9.9ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 49.9ms\n",
      "Speed: 2.1ms preprocess, 49.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 46.2ms\n",
      "Speed: 14.1ms preprocess, 46.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 145.6ms\n",
      "Speed: 7.9ms preprocess, 145.6ms inference, 5.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 162.3ms\n",
      "Speed: 8.1ms preprocess, 162.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 160.8ms\n",
      "Speed: 8.2ms preprocess, 160.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 174.3ms\n",
      "Speed: 16.9ms preprocess, 174.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 155.7ms\n",
      "Speed: 8.7ms preprocess, 155.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 169.4ms\n",
      "Speed: 8.0ms preprocess, 169.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 157.5ms\n",
      "Speed: 6.1ms preprocess, 157.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 151.7ms\n",
      "Speed: 15.5ms preprocess, 151.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 152.7ms\n",
      "Speed: 4.1ms preprocess, 152.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 161.8ms\n",
      "Speed: 0.0ms preprocess, 161.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 165.4ms\n",
      "Speed: 9.9ms preprocess, 165.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 158.8ms\n",
      "Speed: 7.2ms preprocess, 158.8ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 169.4ms\n",
      "Speed: 9.0ms preprocess, 169.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 153.3ms\n",
      "Speed: 8.4ms preprocess, 153.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 155.2ms\n",
      "Speed: 8.2ms preprocess, 155.2ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 150.1ms\n",
      "Speed: 6.8ms preprocess, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 196.6ms\n",
      "Speed: 9.1ms preprocess, 196.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 188.1ms\n",
      "Speed: 6.3ms preprocess, 188.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 149.6ms\n",
      "Speed: 23.9ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 154.2ms\n",
      "Speed: 9.1ms preprocess, 154.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 66.1ms\n",
      "Speed: 6.3ms preprocess, 66.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 65.1ms\n",
      "Speed: 11.4ms preprocess, 65.1ms inference, 5.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 68.9ms\n",
      "Speed: 6.3ms preprocess, 68.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 75.6ms\n",
      "Speed: 0.0ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 63.3ms\n",
      "Speed: 10.1ms preprocess, 63.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 63.6ms\n",
      "Speed: 3.4ms preprocess, 63.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 69.5ms\n",
      "Speed: 4.5ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 69.4ms\n",
      "Speed: 10.6ms preprocess, 69.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 66.9ms\n",
      "Speed: 3.1ms preprocess, 66.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 155.2ms\n",
      "Speed: 5.6ms preprocess, 155.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 152.1ms\n",
      "Speed: 2.6ms preprocess, 152.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 150.9ms\n",
      "Speed: 4.2ms preprocess, 150.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 144.1ms\n",
      "Speed: 7.0ms preprocess, 144.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 136.2ms\n",
      "Speed: 13.4ms preprocess, 136.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 137.4ms\n",
      "Speed: 1.0ms preprocess, 137.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 147.0ms\n",
      "Speed: 5.9ms preprocess, 147.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 133.3ms\n",
      "Speed: 7.2ms preprocess, 133.3ms inference, 9.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 141.9ms\n",
      "Speed: 7.8ms preprocess, 141.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 135.8ms\n",
      "Speed: 11.8ms preprocess, 135.8ms inference, 11.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 147.2ms\n",
      "Speed: 9.4ms preprocess, 147.2ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 1 dog, 144.8ms\n",
      "Speed: 6.5ms preprocess, 144.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 1 dog, 138.6ms\n",
      "Speed: 7.8ms preprocess, 138.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 1 dog, 151.9ms\n",
      "Speed: 15.3ms preprocess, 151.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 154.3ms\n",
      "Speed: 16.6ms preprocess, 154.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 146.4ms\n",
      "Speed: 4.2ms preprocess, 146.4ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 151.4ms\n",
      "Speed: 19.9ms preprocess, 151.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 90.1ms\n",
      "Speed: 15.8ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 63.2ms\n",
      "Speed: 6.8ms preprocess, 63.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 63.2ms\n",
      "Speed: 4.4ms preprocess, 63.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 67.2ms\n",
      "Speed: 12.1ms preprocess, 67.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 68.5ms\n",
      "Speed: 1.7ms preprocess, 68.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 62.9ms\n",
      "Speed: 2.2ms preprocess, 62.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 73.5ms\n",
      "Speed: 0.0ms preprocess, 73.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 63.1ms\n",
      "Speed: 5.1ms preprocess, 63.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 65.2ms\n",
      "Speed: 6.3ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 58.4ms\n",
      "Speed: 4.4ms preprocess, 58.4ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n",
      "Bounding box\n",
      "Overlay\n",
      "\n",
      "0: 480x640 1 person, 64.7ms\n",
      "Speed: 8.4ms preprocess, 64.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "frame saved\n",
      "frame preprocessed\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify, send_from_directory\n",
    "from flask import Flask, request, send_file, abort, Response\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Set up directories for uploads and processed videos\n",
    "UPLOAD_FOLDER = 'static/uploads'\n",
    "PROCESSED_FOLDER = 'static/processed'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "os.makedirs(PROCESSED_FOLDER, exist_ok=True)\n",
    "\n",
    "# Load the fine-tuned MoviNet model\n",
    "saved_model_path=\"C:/Users/amazm/University/Final Year Project/Website/saved_model\"\n",
    "yolo_model=YOLO('yolov8n.pt')\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    frame = cv2.resize(frame, (224, 224))  # Resize to model input size\n",
    "    frame = frame / 255.0  # Normalize to range [0, 1]\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add batch dimension\n",
    "    frame = np.expand_dims(frame, axis=0)  # Add temporal dimension\n",
    "    return frame.astype(np.float32)\n",
    "\n",
    "def detect_objects(frame):\n",
    "    \"\"\"Detect persons in a frame using YOLOv8.\"\"\"\n",
    "    results = yolo_model(frame)\n",
    "    detections = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy().astype(int)  # Class IDs\n",
    "    return [(bbox, conf) for bbox, conf, cls_id in zip(detections, confidences, class_ids) if cls_id == 0]  # Filter persons\n",
    "\n",
    "\n",
    "\n",
    "def process_video(input_video_path, output_video_path):\n",
    "    print(f\"Input_video={input_video_path}\")\n",
    "    model = tf.saved_model.load(saved_model_path)\n",
    "    infer = model.signatures[\"serving_default\"]\n",
    "    #yolo_model=YOLO('yolov8n.pt')\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    print(\"video open\")\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the input video.\")\n",
    "        exit()\n",
    "\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print('frame,height,width got')\n",
    "# Define codec and create VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    print('out declared')\n",
    "# Variables to track fall detection and bounding box\n",
    "    fall_detected = False\n",
    "    tracker = None  # To hold the OpenCV tracker\n",
    "    fall_occurred = False  # To track if fall has already occurred\n",
    "    print('variable initialized')\n",
    "# Process video frame by frame\n",
    "    frame_number = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "    # Initialize tracker if not already initialized\n",
    "        if tracker is None and not fall_occurred:\n",
    "            # Detect persons using YOLOv8\n",
    "            detections = detect_objects(frame)\n",
    "            print('frame detected')\n",
    "            if detections:\n",
    "                bbox, _ = detections[0]  # Take the first detected person\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                tracker = cv2.TrackerCSRT_create()  # Robust tracker\n",
    "                tracker.init(frame, (x1, y1, x2 - x1, y2 - y1))  # Initialize tracker with bounding box\n",
    "\n",
    "    # Update tracker\n",
    "        if tracker is not None:\n",
    "            success, tracked_bbox = tracker.update(frame)\n",
    "            if success:\n",
    "                x, y, w, h = map(int, tracked_bbox)\n",
    "            else:\n",
    "                tracker = None  # Reset tracker if tracking fails\n",
    "\n",
    "    # Preprocess the frame for MoviNet\n",
    "        processed_frame = preprocess_frame(frame)\n",
    "        print('frame preprocessed')\n",
    "        try:\n",
    "        # Run inference\n",
    "            predictions = infer(image=processed_frame)\n",
    "            raw_output = predictions['classifier_head_2'].numpy()\n",
    "            fall_probability = raw_output[0][0]  # Probability for \"fall\" class\n",
    "            nofall_probability = raw_output[0][1]  # Probability for \"nofall\" class\n",
    "            fall_detected = fall_probability > nofall_probability\n",
    "        except Exception as e:\n",
    "            print(f\"Error during MoviNet inference: {e}\")\n",
    "\n",
    "    # Once fall is detected, keep the rectangle red and text \"FALL DETECTED\"\n",
    "        if fall_detected and not fall_occurred:\n",
    "            fall_occurred = True  # Mark that fall has occurred\n",
    "\n",
    "    # Draw bounding box and text\n",
    "        if tracker is not None:\n",
    "            color = (0, 0, 255) if fall_occurred else (0, 255, 0)  # Red for fall, green otherwise\n",
    "            thickness = 5  # Thicker bounding box for better visibility\n",
    "            label = \"FALL DETECTED\" if fall_occurred else \"Person\"\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness)\n",
    "        # More elegant text: bigger and shadowed\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)\n",
    "        print('Bounding box')\n",
    "    # Overlay status text with improved design\n",
    "        status_text = \"FALL DETECTED\" if fall_occurred else \"NO FALL\"\n",
    "        status_color = (0, 0, 255) if fall_occurred else (0, 255, 0)\n",
    "    # Add shadow to status text for better visibility\n",
    "        cv2.putText(frame, status_text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "        cv2.putText(frame, status_text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, status_color, 3, cv2.LINE_AA)\n",
    "        print('Overlay')\n",
    "    # Adjust bounding box around the person if necessary (in case the person is outside the box)\n",
    "        if fall_occurred:\n",
    "        # Detect the person again if fall occurred and update tracker accordingly\n",
    "            detections = detect_objects(frame)\n",
    "            if detections:\n",
    "                bbox, _ = detections[0]  # Get updated bounding box\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "            # Increase bounding box size to ensure it fully includes the person after falling\n",
    "                margin = 20  # Add margin to the bounding box\n",
    "                x1, y1 = max(0, x1 - margin), max(0, y1 - margin)\n",
    "                x2, y2 = min(width, x2 + margin), min(height, y2 + margin)\n",
    "                x, y, w, h = x1, y1, x2 - x1, y2 - y1\n",
    "                tracker = cv2.TrackerCSRT_create()  # Reinitialize the tracker to better fit the new position\n",
    "                tracker.init(frame, (x, y, w, h))\n",
    "\n",
    "    # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "        print('frame saved')\n",
    "        frame_number += 1\n",
    "\n",
    "# Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "# Report results\n",
    "    print(f\"Video saved to: {output_video_path}\")\n",
    "# Flask Routes\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/FallDetection')\n",
    "def FallDetection():\n",
    "    return render_template('FallDetection.html')\n",
    "\n",
    "@app.route('/live-detection')\n",
    "def livedetection():\n",
    "    return render_template('live-detection.html')\n",
    "\n",
    "@app.route('/Login')\n",
    "def Login():\n",
    "    return render_template('Login.html')\n",
    "\n",
    "@app.route('/Mental')\n",
    "def Mental():\n",
    "    return render_template('Mental.html')\n",
    "\n",
    "@app.route('/ModulesPage')\n",
    "def ModulesPage():\n",
    "    return render_template('ModulesPage.html')\n",
    "\n",
    "@app.route('/Report')\n",
    "def Report():\n",
    "    return render_template('Report.html')\n",
    "\n",
    "@app.route('/SignUp')\n",
    "def SignUp():\n",
    "    return render_template('SignUp.html')\n",
    "    \n",
    "@app.route('/upload-video', methods=['GET', 'POST'])\n",
    "def uploadvideo():\n",
    "    if request.method == 'POST':\n",
    "        if 'video' not in request.files:\n",
    "            return jsonify({'error': 'No video file found in the request'}), 400\n",
    "        \n",
    "        video = request.files['video']\n",
    "        if not video.filename.endswith(('.mp4', '.avi', '.mov', '.webm')):\n",
    "            return jsonify({'error': 'Unsupported video format'}), 400\n",
    "        \n",
    "        upload_path = os.path.join(UPLOAD_FOLDER, video.filename)\n",
    "        upload_path = os.path.normpath(upload_path).replace(\"\\\\\", \"/\")\n",
    "        print(f\"Video uploaded to: {upload_path}\")\n",
    "        video.save(upload_path)\n",
    "        \n",
    "        file_name, file_extension = os.path.splitext(video.filename)\n",
    "        new_extension = '.mp4' if file_extension.lower() != '.avi' else '.avi'\n",
    "\n",
    "        processed_path = os.path.join(PROCESSED_FOLDER, f\"{file_name}{new_extension}\")\n",
    "        processed_path = os.path.normpath(processed_path).replace(\"\\\\\", \"/\")\n",
    "        print(f\"Processing video: {processed_path}\")\n",
    "\n",
    "        try:\n",
    "            process_video(upload_path, processed_path)  # Process the video\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing video: {e}\")\n",
    "            return jsonify({'error': f\"Processing failed: {str(e)}\"}), 500\n",
    "\n",
    "        if not os.path.exists(processed_path):\n",
    "            return jsonify({'error': 'Processed video not found'}), 500\n",
    "\n",
    "        processed_video_url = f'/static/processed/{os.path.basename(processed_path)}'\n",
    "        print(f\"Processed video URL: {processed_video_url}\")\n",
    "        return jsonify({'processedVideoUrl': processed_video_url})\n",
    "    \n",
    "    return render_template('upload-video.html')\n",
    "\n",
    "    \n",
    "@app.route('/download/<filename>')\n",
    "def download_processed_video(filename):\n",
    "    \"\"\" Serve processed video as a file download \"\"\"\n",
    "    file_path = os.path.join(PROCESSED_FOLDER, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File {file_path} not found.\")\n",
    "        return abort(404)\n",
    "\n",
    "    try:\n",
    "        return send_file(file_path, as_attachment=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending file: {e}\")\n",
    "        return jsonify({'error': f\"Download failed: {str(e)}\"}), 500\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fa26a-e44b-4d12-b065-6393602e8068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
